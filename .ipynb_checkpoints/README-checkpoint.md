# MSBA-Portfolio-UgoAchara

# ðŸ“Š Case Competition Modeling Overview  
This repository contains the full analytical workflow used to understand customer behavior, quantify churn risk, and build a highâ€‘performance prediction system. The project integrates **Kâ€‘Means Clustering**, **Logistic Regression**, and **XGBoost**, combining segmentation, interpretability, and predictive accuracy.

---

## ðŸ”¹ 1. Kâ€‘Means Clustering: Customer Segmentation  
**Objective:** Identify natural customer groups based on behavior, service usage, and account characteristics.

### **Process**
- Applied oneâ€‘hot encoding to categorical variables and standardized numeric features.  
- Selected features representing engagement, service adoption, and billing patterns.  
- Tested multiple values of *k* using the **Elbow Method** and **Silhouette Score**.  
- Used **PCA** to visualize clusters and improve interpretability.

### **Outcome**
Kâ€‘Means revealed distinct customer personas, such as:  
- Shortâ€‘tenure, monthâ€‘toâ€‘month customers with high churn risk  
- Longâ€‘tenure, contractâ€‘based customers with low churn risk  
- Moderateâ€‘tenure customers with high techâ€‘support usage  

These segments informed targeted retention strategies and validated patterns seen in supervised models.

---

## ðŸ”¹ 2. Logistic Regression: Interpretable Churn Prediction  
**Objective:** Quantify the direction and strength of churn drivers using a transparent, businessâ€‘friendly model.

### **Process**
- Split data into training and testing sets.  
- Applied class balancing to address churn imbalance.  
- Standardized numeric variables and encoded categorical features.  
- Trained logistic regression with L2 regularization to prevent overfitting.

### **Key Insights**
- Monthâ€‘toâ€‘month contracts significantly increase churn probability.  
- Lack of tech support is a major churn driver.  
- Higher monthly charges correlate with higher churn risk.  
- Longer tenure strongly reduces churn likelihood.

Logistic Regression provided clear interpretability and validated the behavioral patterns identified in clustering.

---

## ðŸ”¹ 3. XGBoost: Highâ€‘Performance Predictive Modeling  
**Objective:** Build a powerful, nonâ€‘linear model capable of accurately identifying highâ€‘risk customers.

### **Process**
- Tuned hyperparameters (learning rate, max depth, number of estimators).  
- Used crossâ€‘validation to ensure generalization.  
- Evaluated performance using AUC, accuracy, precision, and recall.  
- Extracted feature importance to understand model behavior.

### **Results**
XGBoost delivered the strongest predictive performance, capturing complex interactions and ranking the most influential features, including:  
- Contract type  
- Tenure  
- Monthly charges  
- Tech support  
- Internet service type  

These results aligned with both the logistic regression coefficients and the Kâ€‘Means cluster profiles.

---

## ðŸ”¹ Integrated Interpretation  
Using all three models together created a comprehensive analytical framework:

| Model | Purpose | Strength |
|-------|---------|----------|
| **Kâ€‘Means** | Discover customer personas | Unsupervised segmentation |
| **Logistic Regression** | Explain churn drivers | High interpretability |
| **XGBoost** | Predict churn with high accuracy | Captures complex patterns |

This combined approach enabled targeted, dataâ€‘driven retention strategies with measurable business impact.

---

If you want, I can also format:

- A shorter README version  
- A slideâ€‘ready version  
- A technical appendix version  
- A version with code blocks included  

Just tell me the style you want next.
